
[2025-08-17 10:29:59]
üì¶ Installing pandas ...
----------------------------------------

[2025-08-17 10:30:20]
üì¶ Installing requests ...
----------------------------------------

[2025-08-17 10:30:25]
üì¶ Installing lxml ...
----------------------------------------

[2025-08-17 10:30:28]
üìú Executing Code:
import pandas as pd
import requests

url = "https://en.wikipedia.org/wiki/List_of_highest-grossing_films"
response = requests.get(url)
tables = pd.read_html(response.content)

# The main table is usually the first one
df = tables[0]

summary = {
    "table_shape": df.shape,
    "columns": list(df.columns),
    "head": df.head(3).to_dict(orient="records"),
}

with open("uploads/d7b17f83-9c79-46fa-9dff-952b21234904/metadata.txt", "w") as f:
    f.write(f"Scraped data from {url}.\n")
    f.write(f'Table Shape: {summary["table_shape"]}\n')
    f.write(f'Columns: {summary["columns"]}\n')
    f.write(f'First 3 rows: {summary["head"]}\n')

print(f"Successfully scraped data. Summary saved to metadata.txt")

----------------------------------------

[2025-08-17 10:30:31]
‚úÖ Code executed successfully:
Successfully scraped data. Summary saved to metadata.txt

----------------------------------------

[2025-08-17 10:30:52]
‚úÖ pandas already installed.
----------------------------------------

[2025-08-17 10:30:52]
‚úÖ requests already installed.
----------------------------------------

[2025-08-17 10:30:52]
‚úÖ lxml already installed.
----------------------------------------

[2025-08-17 10:30:52]
‚úÖ numpy already installed.
----------------------------------------

[2025-08-17 10:30:52]
üì¶ Installing matplotlib ...
----------------------------------------

[2025-08-17 10:31:06]
üì¶ Installing seaborn ...
----------------------------------------

[2025-08-17 10:31:09]
üìú Executing Code:
import pandas as pd
import requests
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import io
import base64
import json

# Step 1: Fetch and clean data
url = "https://en.wikipedia.org/wiki/List_of_highest-grossing_films"
response = requests.get(url)
tables = pd.read_html(response.content)
df = tables[0]

# Clean the 'Worldwide gross' column
df["Worldwide gross"] = (
    df["Worldwide gross"].astype(str).str.replace(r"\$|,", "", regex=True)
)
df["Worldwide gross"] = pd.to_numeric(df["Worldwide gross"])

# Clean Rank and Peak columns
df["Rank"] = pd.to_numeric(df["Rank"])
df["Peak"] = pd.to_numeric(df["Peak"])

# --- Answer Questions ---

# 1. How many $2 bn movies were released before 2000?
before_2000_2bn = df[(df["Worldwide gross"] >= 2_000_000_000) & (df["Year"] < 2000)]
answer1 = len(before_2000_2bn)

# 2. Which is the earliest film that grossed over $1.5 bn?
over_1_5bn = df[df["Worldwide gross"] >= 1_500_000_000]
earliest_film = over_1_5bn.loc[over_1_5bn["Year"].idxmin()]
answer2 = earliest_film["Title"]

# 3. What's the correlation between the Rank and Peak?
correlation = df["Rank"].corr(df["Peak"])
answer3 = correlation

# 4. Draw a scatterplot of Rank and Peak
plt.figure(figsize=(8, 6))
sns.regplot(x="Rank", y="Peak", data=df, line_kws={"color": "red", "linestyle": "--"})
plt.title("Rank vs. Peak of Highest-Grossing Films")
plt.xlabel("Rank")
plt.ylabel("Peak")
plt.grid(True)

# Save plot to a base64 string
buf = io.BytesIO()
plt.savefig(buf, format="png", bbox_inches="tight")
buf.seek(0)
img_base64 = base64.b64encode(buf.read()).decode("utf-8")
answer4 = f"data:image/png;base64,{img_base64}"
plt.close()

# --- Save results ---
final_answers = [str(answer1), str(answer2), str(answer3), answer4]

with open("uploads/d7b17f83-9c79-46fa-9dff-952b21234904/result.json", "w") as f:
    json.dump(final_answers, f)

# Append a summary of answers to metadata.txt
with open("uploads/d7b17f83-9c79-46fa-9dff-952b21234904/metadata.txt", "a") as f:
    f.write("\n--- Analysis Results ---\n")
    f.write(f"Q1: $2bn movies before 2000: {answer1}\n")
    f.write(f"Q2: Earliest >$1.5bn film: {answer2}\n")
    f.write(f"Q3: Rank/Peak Correlation: {answer3:.4f}\n")
    f.write("Q4: Scatterplot generated and saved.\n")

print("Analysis complete. Results saved to result.json and metadata.txt")

----------------------------------------

[2025-08-17 10:31:13]
‚ùå Execution error:
Traceback (most recent call last):
  File "pandas/_libs/lib.pyx", line 2407, in pandas._libs.lib.maybe_convert_numeric
ValueError: Unable to parse string "T2257844554"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/azureuser/TDS_project2/uploads/d7b17f83-9c79-46fa-9dff-952b21234904/job_/script.py", line 18, in <module>
    df['Worldwide gross'] = pd.to_numeric(df['Worldwide gross'])
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/azureuser/TDS_project2/venv/lib/python3.11/site-packages/pandas/core/tools/numeric.py", line 235, in to_numeric
    values, new_mask = lib.maybe_convert_numeric(  # type: ignore[call-overload]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "pandas/_libs/lib.pyx", line 2449, in pandas._libs.lib.maybe_convert_numeric
ValueError: Unable to parse string "T2257844554" at position 3

----------------------------------------

[2025-08-17 10:31:33]
‚úÖ pandas already installed.
----------------------------------------

[2025-08-17 10:31:33]
‚úÖ requests already installed.
----------------------------------------

[2025-08-17 10:31:33]
‚úÖ lxml already installed.
----------------------------------------

[2025-08-17 10:31:33]
‚úÖ numpy already installed.
----------------------------------------

[2025-08-17 10:31:33]
‚úÖ matplotlib already installed.
----------------------------------------

[2025-08-17 10:31:33]
‚úÖ seaborn already installed.
----------------------------------------

[2025-08-17 10:31:33]
üìú Executing Code:
import pandas as pd
import requests
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import io
import base64
import json

# Step 1: Fetch and clean data
url = "https://en.wikipedia.org/wiki/List_of_highest-grossing_films"
response = requests.get(url)
tables = pd.read_html(response.content)
df = tables[0]

# Clean the 'Worldwide gross' column by removing any non-digit characters
df["Worldwide gross"] = (
    df["Worldwide gross"].astype(str).str.replace(r"[^0-9]", "", regex=True)
)
df["Worldwide gross"] = pd.to_numeric(df["Worldwide gross"])

# Clean Rank and Peak columns
df["Rank"] = pd.to_numeric(df["Rank"])
# The 'Peak' column can also contain non-numeric characters from references
df["Peak"] = df["Peak"].astype(str).str.replace(r"[^0-9]", "", regex=True)
df["Peak"] = pd.to_numeric(df["Peak"])

# --- Answer Questions ---

# 1. How many $2 bn movies were released before 2000?
before_2000_2bn = df[(df["Worldwide gross"] >= 2_000_000_000) & (df["Year"] < 2000)]
answer1 = len(before_2000_2bn)

# 2. Which is the earliest film that grossed over $1.5 bn?
over_1_5bn = df[df["Worldwide gross"] >= 1_500_000_000]
earliest_film = over_1_5bn.loc[over_1_5bn["Year"].idxmin()]
answer2 = earliest_film["Title"]

# 3. What's the correlation between the Rank and Peak?
correlation = df["Rank"].corr(df["Peak"])
answer3 = correlation

# 4. Draw a scatterplot of Rank and Peak
plt.figure(figsize=(8, 6))
sns.regplot(x="Rank", y="Peak", data=df, line_kws={"color": "red", "linestyle": "--"})
plt.title("Rank vs. Peak of Highest-Grossing Films")
plt.xlabel("Rank")
plt.ylabel("Peak")
plt.grid(True)

# Save plot to a base64 string
buf = io.BytesIO()
plt.savefig(buf, format="png", bbox_inches="tight")
buf.seek(0)
img_base64 = base64.b64encode(buf.read()).decode("utf-8")
answer4 = f"data:image/png;base64,{img_base64}"
plt.close()

# --- Save results ---
final_answers = [str(answer1), str(answer2), str(answer3), answer4]

with open("uploads/d7b17f83-9c79-46fa-9dff-952b21234904/result.json", "w") as f:
    json.dump(final_answers, f)

# Append a summary of answers to metadata.txt
with open("uploads/d7b17f83-9c79-46fa-9dff-952b21234904/metadata.txt", "a") as f:
    f.write("\n--- Analysis Results ---\n")
    f.write(f"Q1: $2bn movies before 2000: {answer1}\n")
    f.write(f"Q2: Earliest >$1.5bn film: {answer2}\n")
    f.write(f"Q3: Rank/Peak Correlation: {answer3:.4f}\n")
    f.write("Q4: Scatterplot generated and saved.\n")

print("Analysis complete. Results saved to result.json and metadata.txt")

----------------------------------------

[2025-08-17 10:31:35]
‚úÖ Code executed successfully:
Analysis complete. Results saved to result.json and metadata.txt

----------------------------------------

[2025-08-17 10:31:50]
üìú Executing Code:

----------------------------------------

[2025-08-17 10:31:50]
‚úÖ Code executed successfully:

----------------------------------------
